{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bab3f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting timm\n",
      "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
      "\u001b[K     |████████████████████████████████| 431 kB 39.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from timm) (0.11.0a0)\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.8/site-packages (from timm) (1.11.0a0+b6df043)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.4->timm) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torchvision->timm) (1.21.4)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /opt/conda/lib/python3.8/site-packages (from torchvision->timm) (8.2.0)\n",
      "Installing collected packages: timm\n",
      "Successfully installed timm-0.5.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#importing libraries for testing purposes\n",
    "\n",
    "#Using code from https://developer.nvidia.com/blog/accelerating-inference-up-to-6x-faster-in-pytorch-with-torch-tensorrt/\n",
    "\n",
    "! pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "370a02ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b0_ra-3dd342df.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_ra-3dd342df.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_tensorrt\n",
    "import timm\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "torch.hub._validate_not_a_forked_repo=lambda a,b,c: True\n",
    "\n",
    "efficientnet_b0 = timm.create_model('efficientnet_b0',pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfb5453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(efficientnet_b0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de24ba40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1000])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = efficientnet_b0.eval().to(\"cuda\")\n",
    "detections_batch = model(torch.randn(128, 3, 224, 224).to(\"cuda\"))\n",
    "detections_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2ddeaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "\n",
    "def benchmark(model, input_shape=(1024, 3, 512, 512), dtype='fp32', nwarmup=50, nruns=1000):\n",
    "    input_data = torch.randn(input_shape)\n",
    "    input_data = input_data.to(\"cuda\")\n",
    "    if dtype=='fp16':\n",
    "        input_data = input_data.half()\n",
    "        \n",
    "    print(\"Warm up ...\")\n",
    "    with torch.no_grad():\n",
    "        for _ in range(nwarmup):\n",
    "            features = model(input_data)\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"Start timing ...\")\n",
    "    timings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(1, nruns+1):\n",
    "            start_time = time.time()\n",
    "            pred_loc  = model(input_data)\n",
    "            torch.cuda.synchronize()\n",
    "            end_time = time.time()\n",
    "            timings.append(end_time - start_time)\n",
    "            if i%10==0:\n",
    "                print('Iteration %d/%d, avg batch time %.2f ms'%(i, nruns, np.mean(timings)*1000))\n",
    "\n",
    "    print(\"Input shape:\", input_data.size())\n",
    "    print('Average throughput: %.2f images/second'%(input_shape[0]/np.mean(timings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c236dcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/100, avg batch time 7.90 ms\n",
      "Iteration 20/100, avg batch time 7.88 ms\n",
      "Iteration 30/100, avg batch time 7.89 ms\n",
      "Iteration 40/100, avg batch time 7.88 ms\n",
      "Iteration 50/100, avg batch time 7.87 ms\n",
      "Iteration 60/100, avg batch time 7.87 ms\n",
      "Iteration 70/100, avg batch time 7.86 ms\n",
      "Iteration 80/100, avg batch time 7.87 ms\n",
      "Iteration 90/100, avg batch time 7.88 ms\n",
      "Iteration 100/100, avg batch time 7.87 ms\n",
      "Input shape: torch.Size([1, 3, 224, 224])\n",
      "Average throughput: 127.03 images/second\n"
     ]
    }
   ],
   "source": [
    "model = efficientnet_b0.eval().to(\"cuda\")\n",
    "benchmark(model, input_shape=(1, 3, 224, 224), nruns=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e78d61d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/100, avg batch time 4.89 ms\n",
      "Iteration 20/100, avg batch time 4.89 ms\n",
      "Iteration 30/100, avg batch time 4.89 ms\n",
      "Iteration 40/100, avg batch time 4.89 ms\n",
      "Iteration 50/100, avg batch time 4.89 ms\n",
      "Iteration 60/100, avg batch time 4.89 ms\n",
      "Iteration 70/100, avg batch time 4.89 ms\n",
      "Iteration 80/100, avg batch time 4.89 ms\n",
      "Iteration 90/100, avg batch time 4.89 ms\n",
      "Iteration 100/100, avg batch time 4.89 ms\n",
      "Input shape: torch.Size([1, 3, 224, 224])\n",
      "Average throughput: 204.50 images/second\n"
     ]
    }
   ],
   "source": [
    "traced_model = torch.jit.trace(model, torch.randn((1,3,224,224)).to(\"cuda\"))\n",
    "torch.jit.save(traced_model, \"efficientnet_b0_traced.jit.pt\")\n",
    "benchmark(traced_model, input_shape=(1, 3, 224, 224), nruns=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8ea107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29bbcb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [Torch-TensorRT] - For input x.1, found user specified input dtype as Float16, however when inspecting the graph, the input type expected was inferred to be Float\n",
      "The compiler is going to use the user setting Float16\n",
      "This conflict may cause an error at runtime due to partial compilation being enabled and therefore\n",
      "compatibility with PyTorch's data type convention is required.\n",
      "If you do indeed see errors at runtime either:\n",
      "- Remove the dtype spec for x.1\n",
      "- Disable partial compilation by setting require_full_compilation to True\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Detected invalid timing cache, setup a local cache instead\n"
     ]
    }
   ],
   "source": [
    "trt_model = torch_tensorrt.compile(model, \n",
    "    inputs= [torch_tensorrt.Input((1, 3, 224, 224),dtype=torch.half)],\n",
    "    enabled_precisions= {torch.float, torch.half} # Run with FP16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "659a27f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveScriptModule(original_name=EfficientNet_trt)\n"
     ]
    }
   ],
   "source": [
    "print(trt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9581f112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trt_model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f41ca3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveScriptModule(original_name=EfficientNet_trt)\n"
     ]
    }
   ],
   "source": [
    "print(trt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6653ab2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/100, avg batch time 2.19 ms\n",
      "Iteration 20/100, avg batch time 2.19 ms\n",
      "Iteration 30/100, avg batch time 2.18 ms\n",
      "Iteration 40/100, avg batch time 2.18 ms\n",
      "Iteration 50/100, avg batch time 2.18 ms\n",
      "Iteration 60/100, avg batch time 2.18 ms\n",
      "Iteration 70/100, avg batch time 2.18 ms\n",
      "Iteration 80/100, avg batch time 2.18 ms\n",
      "Iteration 90/100, avg batch time 2.14 ms\n",
      "Iteration 100/100, avg batch time 2.05 ms\n",
      "Input shape: torch.Size([1, 3, 224, 224])\n",
      "Average throughput: 486.96 images/second\n"
     ]
    }
   ],
   "source": [
    "benchmark(trt_model, input_shape=(1, 3, 224, 224), nruns=100, dtype=\"fp16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca11e632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveScriptModule(original_name=EfficientNet_trt)\n"
     ]
    }
   ],
   "source": [
    "print(trt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c3ae931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#traced_mod_trt = torch.jit.trace(trt_model, torch.randn((1,3,224,224)).to(\"cuda\"))\n",
    "torch.jit.save(trt_model, \"efficientnet_b0_traced_trt4.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea00e390",
   "metadata": {},
   "outputs": [],
   "source": [
    "#traced_mod_trt = torch.jit.trace(trt_model, torch.randn((1,3,224,224)).to(\"cuda\"))\n",
    "efficientnet_b0_traced_trt4 = torch.jit.load(\"efficientnet_b0_traced_trt2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad182af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/100, avg batch time 2.36 ms\n",
      "Iteration 20/100, avg batch time 2.37 ms\n",
      "Iteration 30/100, avg batch time 2.36 ms\n",
      "Iteration 40/100, avg batch time 2.35 ms\n",
      "Iteration 50/100, avg batch time 2.15 ms\n",
      "Iteration 60/100, avg batch time 2.01 ms\n",
      "Iteration 70/100, avg batch time 1.91 ms\n",
      "Iteration 80/100, avg batch time 1.83 ms\n",
      "Iteration 90/100, avg batch time 1.78 ms\n",
      "Iteration 100/100, avg batch time 1.73 ms\n",
      "Input shape: torch.Size([1, 3, 224, 224])\n",
      "Average throughput: 578.62 images/second\n"
     ]
    }
   ],
   "source": [
    "benchmark(efficientnet_b0_traced_trt4, input_shape=(1, 3, 224, 224), nruns=100, dtype=\"fp16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b816a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
