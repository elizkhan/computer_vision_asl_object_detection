{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2cdfcc6",
   "metadata": {},
   "source": [
    "# Example of Converting Pytorch model to tensorrt\n",
    "---\n",
    "We are directly following the guide at https://developer.nvidia.com/blog/accelerating-inference-up-to-6x-faster-in-pytorch-with-torch-tensorrt/ with a few modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75656a4c",
   "metadata": {},
   "source": [
    "\n",
    "Using the __Nvidia Deep Learning AMI__ and using the following commands to access the Pytorch Nvidia Docker image.\n",
    "\n",
    "```shell\n",
    "jupyter lab --allow-root --ip=0.0.0.0 --NotebookApp.token='TensorRT' --port 8888\n",
    "docker run --rm -it --ipc=host -v ~/foldername:/workspace/foldername --gpus all --net=host nvcr.io/nvidia/pytorch:21.11-py3\n",
    "```\n",
    "\n",
    "Use __IPv4:8888__ to access jupyter lab from browser. The IPv4 is the public IP provided from AWS.\n",
    "The token is __TensorRT__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a2cea54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting timm\n",
      "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
      "\u001b[K     |████████████████████████████████| 431 kB 30.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.8/site-packages (from timm) (1.11.0a0+b6df043)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from timm) (0.11.0a0)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.4->timm) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torchvision->timm) (1.21.4)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /opt/conda/lib/python3.8/site-packages (from torchvision->timm) (8.2.0)\n",
      "Installing collected packages: timm\n",
      "Successfully installed timm-0.5.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#importing libraries for testing purposes\n",
    "\n",
    "#Using code from https://developer.nvidia.com/blog/accelerating-inference-up-to-6x-faster-in-pytorch-with-torch-tensorrt/\n",
    "\n",
    "! pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87891c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/efficientnet_b0_ra-3dd342df.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_ra-3dd342df.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_tensorrt\n",
    "import timm\n",
    "import time\n",
    "import numpy as np\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "torch.hub._validate_not_a_forked_repo=lambda a,b,c: True\n",
    "\n",
    "efficientnet_b0 = timm.create_model('efficientnet_b0',pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1d3c6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1000])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = efficientnet_b0.eval().to(\"cuda\")\n",
    "detections_batch = model(torch.randn(128, 3, 224, 224).to(\"cuda\"))\n",
    "detections_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bc2f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "\n",
    "def benchmark(model, input_shape=(1024, 3, 512, 512), dtype='fp32', nwarmup=50, nruns=1000):\n",
    "    input_data = torch.randn(input_shape)\n",
    "    input_data = input_data.to(\"cuda\")\n",
    "    if dtype=='fp16':\n",
    "        input_data = input_data.half()\n",
    "        \n",
    "    print(\"Warm up ...\")\n",
    "    with torch.no_grad():\n",
    "        for _ in range(nwarmup):\n",
    "            features = model(input_data)\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"Start timing ...\")\n",
    "    timings = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(1, nruns+1):\n",
    "            start_time = time.time()\n",
    "            pred_loc  = model(input_data)\n",
    "            torch.cuda.synchronize()\n",
    "            end_time = time.time()\n",
    "            timings.append(end_time - start_time)\n",
    "            if i%10==0:\n",
    "                print('Iteration %d/%d, avg batch time %.2f ms'%(i, nruns, np.mean(timings)*1000))\n",
    "\n",
    "    print(\"Input shape:\", input_data.size())\n",
    "    print('Average throughput: %.2f images/second'%(input_shape[0]/np.mean(timings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfc03faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/100, avg batch time 8.17 ms\n",
      "Iteration 20/100, avg batch time 8.14 ms\n",
      "Iteration 30/100, avg batch time 8.04 ms\n",
      "Iteration 40/100, avg batch time 8.01 ms\n",
      "Iteration 50/100, avg batch time 7.99 ms\n",
      "Iteration 60/100, avg batch time 7.95 ms\n",
      "Iteration 70/100, avg batch time 7.94 ms\n",
      "Iteration 80/100, avg batch time 7.92 ms\n",
      "Iteration 90/100, avg batch time 7.91 ms\n",
      "Iteration 100/100, avg batch time 7.93 ms\n",
      "Input shape: torch.Size([1, 3, 224, 224])\n",
      "Average throughput: 126.03 images/second\n"
     ]
    }
   ],
   "source": [
    "model = efficientnet_b0.eval().to(\"cuda\")\n",
    "benchmark(model, input_shape=(1, 3, 224, 224), nruns=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d063fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/100, avg batch time 5.13 ms\n",
      "Iteration 20/100, avg batch time 4.98 ms\n",
      "Iteration 30/100, avg batch time 4.93 ms\n",
      "Iteration 40/100, avg batch time 4.91 ms\n",
      "Iteration 50/100, avg batch time 4.91 ms\n",
      "Iteration 60/100, avg batch time 4.94 ms\n",
      "Iteration 70/100, avg batch time 4.96 ms\n",
      "Iteration 80/100, avg batch time 4.96 ms\n",
      "Iteration 90/100, avg batch time 4.95 ms\n",
      "Iteration 100/100, avg batch time 4.94 ms\n",
      "Input shape: torch.Size([1, 3, 224, 224])\n",
      "Average throughput: 202.46 images/second\n"
     ]
    }
   ],
   "source": [
    "traced_model = torch.jit.trace(model, torch.randn((1,3,224,224)).to(\"cuda\"))\n",
    "torch.jit.save(traced_model, \"efficientnet_b0_traced.jit.pt\")\n",
    "benchmark(traced_model, input_shape=(1, 3, 224, 224), nruns=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45a04bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [Torch-TensorRT] - For input x.1, found user specified input dtype as Float16, however when inspecting the graph, the input type expected was inferred to be Float\n",
      "The compiler is going to use the user setting Float16\n",
      "This conflict may cause an error at runtime due to partial compilation being enabled and therefore\n",
      "compatibility with PyTorch's data type convention is required.\n",
      "If you do indeed see errors at runtime either:\n",
      "- Remove the dtype spec for x.1\n",
      "- Disable partial compilation by setting require_full_compilation to True\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - The logger passed into createInferBuilder differs from one already provided for an existing builder, runtime, or refitter. TensorRT maintains only a single logger pointer at any given time, so the existing value, which can be retrieved with getLogger(), will be used instead. In order to use a new logger, first destroy all existing builder, runner or refitter objects.\n",
      "\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Mean converter disregards dtype\n",
      "WARNING: [Torch-TensorRT] - Detected invalid timing cache, setup a local cache instead\n"
     ]
    }
   ],
   "source": [
    "trt_model = torch_tensorrt.compile(model, \n",
    "    inputs= [torch_tensorrt.Input((1, 3, 224, 224),dtype=torch.half)],\n",
    "    enabled_precisions= {torch.float, torch.half} # Run with FP16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "624223f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/100, avg batch time 2.35 ms\n",
      "Iteration 20/100, avg batch time 2.34 ms\n",
      "Iteration 30/100, avg batch time 2.34 ms\n",
      "Iteration 40/100, avg batch time 2.34 ms\n",
      "Iteration 50/100, avg batch time 2.20 ms\n",
      "Iteration 60/100, avg batch time 2.05 ms\n",
      "Iteration 70/100, avg batch time 1.94 ms\n",
      "Iteration 80/100, avg batch time 1.86 ms\n",
      "Iteration 90/100, avg batch time 1.79 ms\n",
      "Iteration 100/100, avg batch time 1.74 ms\n",
      "Input shape: torch.Size([1, 3, 224, 224])\n",
      "Average throughput: 574.46 images/second\n"
     ]
    }
   ],
   "source": [
    "benchmark(trt_model, input_shape=(1, 3, 224, 224), nruns=100, dtype=\"fp16\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
